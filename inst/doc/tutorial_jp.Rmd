---
title: "Single-species fish stock assessment with TropFishR"
author: "Tobias K. Mildenberger"
date: "`r Sys.Date()`"
output:
    rmarkdown::html_vignette:
    fig_caption: yes
    number_sections: true
    df_print: paged
    toc: true
    toc_depth: 2
    toc_float:
      collapsed: false  
vignette: >
  %\VignetteIndexEntry{StockAssessmentTutorial}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
bibliography: TropFishR.bib
---

```{r ReaddataLoadLibraries, message=FALSE, include=FALSE, echo=FALSE}
knitr::opts_chunk$set(echo = TRUE,
                      cache = FALSE,
                      warning = FALSE,
                      eval = TRUE,
                      error = FALSE,
                      warning = FALSE,
                      message = FALSE,
                      include = TRUE,
                      collapse = TRUE,
                      comment = "#>",
                      fig.show = "hold",
                      fig.width=8, fig.height=7)
```

このチュートリアルは体長組成データ（Length Frequency Data, LFD）を用いた単一魚種の資源評価を実施するためのパッケージ**`TropFishR`**の使い方を解説する。@Sparre1998bを参考に、このチュートリアルは次の内容を含む。(1) 成長や自然死亡係数などの生物学的な資源の特徴の推定、(2) 漁獲率や選択率などの漁業面での特性の探索、(3) 資源量や資源の状態の評価。この順番は資源の特性を順々に明らかにしていくという点で重要な順番である。ただし、このワークフローにおいて、文献情報などを使えばいくかのステップをスキップすることもできる。
<!--
This tutorial illustrates the application of the **`TropFishR`** package to perform a single-species fish stock assessment with length frequency (LFQ) data. According to @Sparre1998b, this includes following steps: (1) estimation of biological stock characteristics (growth and natural mortality), (2) exploration of fisheries aspects (exploitation rate and selectivity), (3) assessment of stock size and status. The order of the methods is important as they build upon each other in a sequential way. Data from literature might be used to skip a step in this workflow or to compare them to the outcomes of this routine.
--> 


###*TropFishRのインストール*
**`TropFishR`**の最新バージョンはv1.2で3.0.0以上のRのバージョンが必要である。パッケージ自体はCRANから以下のようにダウンロード・インストールできる：
<!--
The current version of **`TropFishR`** (v1.2) requires R $>= 3.0.0$ and can be downloaded from CRAN as follows:
-->

```{r, echo = TRUE, include = TRUE, eval = FALSE}
install.packages("TropFishR", repos = "https://cran.rstudio.com/")
```
パッケージはR環境のもとでロードする。

```{r, eval=FALSE, echo=TRUE}
library(devtools)
install_github("tokami/TropFishR", ref="master")
library(TropFishR)
```
このチュートリアルは"synLFQ7"というパッケージに含まれる体長組成データを用いる。このデータセットはR環境のもとで、次のようにしてロードできる。

```{r}
data("synLFQ7") # サンプルサイズ（sample.no）、体長階級幅の中央値（midLengths）、dates(サンプリング日)、catch（漁獲量）
```

###*資源の生物学的な特徴*
成長・自然死亡・加入パターン・親子関係は重要な生物的な特徴で、個体群動態やYPRモデルにおける入力パラメータとして利用される。

####*成長パラメータ*
一般的に使われる成長パラメータは、フォン・ベルタランフィー成長式（von Bertalanffy growth function, VBGF）における漸近体長($L_{inf}$)、成長係数(K)、0歳時の理論的な体長($t_{0}$)である。ELEFAN(ELectronic LEngth Frequency ANalysis)は、体長頻度分布データからデータを再構成し、それを成長曲線にあてはめることによって$L_{inf}$を推定する [@Pauly1980]。
まずは生データと再構築された体長組成データを可視化することから始めると良い。それによって適切な体長階級とデータの再構築のさいに使われる移動平均の大きさが決定できるようになるだろう。関数 "lfqModify" では体長階級の幅を引数"bin_size"で変更することができる。体長組成の再構築プロセスでは関数"lfqRestructure"を用いる。ここでは引数"MA"で、移動平均のためにつかう体長階級の数を設定し、引数"addl.sqrt"で追加的な変数変換（squareroot transformation）をおこなう（これによって大型個体の重みを減らすことができる）。

```{r Figure 1, echo=TRUE, eval=TRUE, fig.cap="Length frequency data visualised in terms of (a) catches and (b) restructured data with MA = 7."}
# 結果の再現性のため乱数のシードを設定する
set.seed(1)

# 体長階級幅を調整する
synLFQ7a <- lfqModify(synLFQ7, bin_size = 4)

# 生データと再構築された頻度分布データを見比べる
lfqbin <- lfqRestructure(synLFQ7a, MA = 5, addl.sqrt = FALSE)
opar <- par(mfrow = c(2,1), mar = c(2,5,2,3), oma = c(2,0,0,0))
plot(lfqbin, Fname = "catch", date.axis = "modern")
plot(lfqbin, Fname = "rcounts", date.axis = "modern")
par(opar)
```
synLFQ7データでは体長階級サイズが4cmで移動平均5で調度良いように見えるので、今後の解析ではこの設定を用いる。最初の推定値$L_{inf}$を得るためには、Powell-Wetherall手法[@Wetherall1987]を用いる。この方法では毎年の漁獲における体長組成分布の代表的な体長階級に対する漁獲のベクトルを必要とする。引数`catch_columns`では、この解析でまとめられる漁獲行列の列を選択できる？？。（The method requires a catch vetor per length class representative for the length distribution in yearly catches instead of the catch matrix. The argument `catch_columns` allows to choose the columns of the catch matrix which will be summarised for the analysis.）ここでは、漁獲行列は２０１６年のものしかないので全ての列を使って、一定の成長パラメータを同時に推定する。

```{r Figure 2, fig.width=6, fig.height=5, echo=TRUE, eval=TRUE, fig.cap="Powell-Wetherall plot to derive an estimate of Linf."}
# Powell Wetherall plot
res_PW <- powell_wetherall(param = synLFQ7a,
                           catch_columns = 1:ncol(synLFQ7a$catch),
                           reg_int = c(10,28))
# show results
paste("Linf =",round(res_PW$Linf_est), "±", round(res_PW$se_Linf))
```
このチュートリアルでは引数`reg_int`が必要である。というのは"powell_wetherall"関数では、ユーザーがどの範囲のデータを回帰に利用するかをインタラクティブに決定する必要があるからである。`reg_int`の引数を使わなければ、グラフ上をクリックすることによってデータの範囲をインタラクティブに設定することができる（より詳細な情報は`help(powell_wetherall)`を参照のこと）。

このチュートリアルで使っているデータに対しては、Powell-Wetherall手法は$L_{inf}$ (± standard error)が`r {round(res_PW$Linf_est,2)}` ± `r {round(res_PW$se_Linf,2)}` cmと推定される。この推定値は図の回帰直線のｘ切片にあたる。この推定値は今後のELEFANを使った解析で用いられる。**`TropFishR`**ではELEFANを用いた次の４つの基本的な方法がある: (i) "K-Scan"; $L_{inf}$を固定し、Kを推定する、(ii) Response Surface Analysis (RSA), (iii) ELEFAN_SA; Simulated annealingを用いたELEFAN, (iv) ELEFAN_GA; 一般的なアルゴリズムを用いたELEFAN。iiからivの３つの方法はKと$L_{inf}$を同時に推定する方法である。

Pwell-Wetherall手法による$L_{inf}$の推定値を使って簡単にKの値を求める場合、ELEFAN関数において`Linf_fix`の引数を以下のように指定する：

```{r, include=TRUE, eval = FALSE, echo=TRUE}
# ELEFAN with K-Scan
res_KScan <- ELEFAN(synLFQ7a, Linf_fix = res_PW$Linf_est,
                    MA=5, addl.sqrt = TRUE, hide.progressbar = TRUE)

# show results
res_KScan$par; res_KScan$Rn_max
```

しかしこの手法は、よりあてはまりが良いかもしれない他の$L_{inf}$とKの組み合わせを網羅的に探索することはできない。一方で、RSAを使うと、Powell-Wetherall手法を使って特定された$L_{inf}$とKの範囲の中でよりあてはまりが良い組み合わせをテストすることができる。または、データのなかの最大体長・最大体長区分・ある範囲における最大体長の平均値などを$L_{inf}$の探索範囲として利用することもできる[@Taylor1958; @Beverton1963]。このデータ・セットでは、Powell-Wetherall法で推定された値プラスマイナス10cmを$L_{inf}$がありそうなだいたいの範囲として設定している。実際にはどんな範囲も指定できるが、範囲が広すぎると計算時間がその分かかってしまう。ただ、広い範囲を指定するとそれだけ広範囲に探索できるので視野は広がる。Kの範囲としては一般的に0.01から2くらいであれば十分で、一般的にも重要であろう。

```{r Figure 3, fig.width=8, eval = FALSE}
# Response surface analyss
res_RSA <- ELEFAN(synLFQ7a, Linf_range = seq(119,139,1), MA = 5,
                  K_range = seq(0.01,2,0.1), addl.sqrt = TRUE,
                  hide.progressbar = TRUE, contour=5)

# show results
res_RSA$par; res_RSA$Rn_max
```

一般的に、RSAによる最初の結果だけをそのまま信じて使うのは推奨されない。というのは、推定値が局所解に陥ってしまっている可能性もあるためである。局所解に陥っていないか確認するため、より細かいパラメータのスケールで再度解析したり、結果をグラフ化してみたりすることをおすすめする。このデータ・セットでは、いかに示す自動化されたコードにおいては、最も高いスコア値は0.781となり、そのときのパラメータは
$L_{inf}$ = 122.2, K = 0.21, $t_{anchor}$ = 0.38となった。

```{r, eval = FALSE, echo=TRUE, include=TRUE}
# find 3 highest score values
n <- length(res_RSA$score_mat)
best_scores <- sort(res_RSA$score_mat,partial=n-0:2)[n-0:2]
ind <- arrayInd(which(res_RSA$score_mat %in% best_scores),
                dim(res_RSA$score_mat))
Ks <- as.numeric(rownames(res_RSA$score_mat)[ind[,1]])
Linfs <- as.numeric(colnames(res_RSA$score_mat)[ind[,2]])

res_loop <- vector("list", 3)
for(i in 1:3){
  tmp <- ELEFAN(synLFQ7a,
                Linf_range = seq(Linfs[i]-2, Linfs[i]+2, 0.2),
                K_range = seq(Ks[i]-0.1, Ks[i]+0.1, 0.05),
                MA = 5,
                addl.sqrt = TRUE,
                hide.progressbar = TRUE,
                contour=5)
  res_loop[[i]] <- cbind(Rn_max=tmp$Rn_max, t(as.matrix(tmp$par)))
}
results <- do.call(rbind, res_loop)
```

RSAは季節的な成長式(seasonalised VBGF (soVBGF))におけるパラメータ（C、$t_s$）を自動的に推定してくれないのでご注意を。もし推定したい場合にはCや$t_s$を固定パラメータとして設定した場合に得られるスコアを比較してCと$t_s$を求めることになる。
	しかし、新しく実装されたELAFAN手法`ELEFAN_SA`（simulated annealingアルゴリズムを利用するもの, [@Xiang2013]）や`ELEFAN_GA`(遺伝的アルゴリズムを使うもの, [@Taylor2016])ではsoVBGFのパラメータも同時に最適化することができる。simulated annealingを用いた最適化手法では、探索プロセスにおける確率性を徐々に減らしていく手法で、より悪い状態を受け入れる確率によって表現されている？？。Powell-Wetherall手法からの結果をもとに、$L_{inf}$の範囲として`r {round(res_PW$Linf_est)}` ± 10 cmを指定し、もう一度パラメータの最適化をおこなった。このときのKの範囲は0.01から1とした. 

```{r Figure 4,  fig.height=5, fig.width=5, eval=TRUE, results="hide", fig.cap="simulated annealingを用いたときのELEFAN手法におけるスコアグラフ。緑の点はコスト関数における最小値、青は個々の繰り返しにおける平均値。赤のラインは'temperature'（悪い状態を受け入れる確率）の値が徐々に下がっていることを示す"}
# simulated annealingをつかったELEFANの実行
res_SA <- ELEFAN_SA(synLFQ7a, SA_time = 60*0.5, SA_temp = 6e5,
                    MA = 5, seasonalised = TRUE, addl.sqrt = FALSE,
                    init_par = list(Linf = 129, K = 0.5, t_anchor = 0.5, C=0.5, ts = 0.5),
                    low_par = list(Linf = 119, K = 0.01, t_anchor = 0, C = 0, ts = 0),
                    up_par = list(Linf = 139, K = 1, t_anchor = 1, C = 1, ts = 1))
# show results
res_SA$par; res_SA$Rn_max
```

	計算時間は"SA_time"で調整でき、この値を大きくすることによって結果の値が変わるかもしれない。そのようなときには、まだ目的関数が安定な最適値に達していないことを示している（スコアグラフで、青と緑の点がオーバーラップすると安定な最適値に達したことを示す）。ここではチュートリアルとしての計算時間を短縮するために0.5秒に設定しているが、この結果でも十分に受け入れられる結果が得られた： $L_{inf}$ = `r {round(res_SA$par$Linf,2)}`, K = `r {round(res_SA$par$K,2)}`, $t_{anchor}$ = `r {round(res_SA$par$t_anchor,2)}`, C = `r {round(res_SA$par$C,2)}`, and $t_s$ = `r {round(res_SA$par$ts,2)}` with a score value ($Rn_{max}$) of `r {round(res_SA$Rn_max,2)}`. 一般には安定した解を得るには'SA_time'を3 - 5秒に増やすことをおすすめする. soVBGFで推定されたパラメータの信頼区間を推定するにはジャックナイフ手法を用いる [@Quenouille1956; @Tukey1958; @Tukey1986]. これは次のコードで自動的に実行できる：

```{r, eval = FALSE, echo = TRUE}
JK <- vector("list", length(synLFQ7a$dates))
for(i in 1:length(synLFQ7a$dates)){
  loop_data <- list(dates = synLFQ7a$dates[-i],
                  midLengths = synLFQ7a$midLengths,
                  catch = synLFQ7a$catch[,-i])
  tmp <- ELEFAN_SA(loop_data, SA_time = 60*0.5, SA_temp = 6e5,
                   MA = 5, addl.sqrt = TRUE,
                   init_par = list(Linf = 129, K = 0.5, t_anchor = 0.5, C=0.5, ts = 0.5),
                   low_par = list(Linf = 119, K = 0.01, t_anchor = 0, C = 0, ts = 0),
                   up_par = list(Linf = 139, K = 1, t_anchor = 1, C = 1, ts = 1),
                   plot = FALSE)
  JK[[i]] <- unlist(c(tmp$par,list(Rn_max=tmp$Rn_max)))
}
JKres <- do.call(cbind, JK)
# mean
JKmeans <- apply(as.matrix(JKres), MARGIN = 1, FUN = mean)
# confidence intervals
JKconf <- apply(as.matrix(JKres), MARGIN = 1, FUN = function(x) quantile(x, probs=c(0.025,0.975)))
JKconf <- t(JKconf)
colnames(JKconf) <- c("lower","upper")

# show results
JKconf
```

Depending on the number of sampling times (columns in the catch matrix) and the "SA_time", this loop can take some time as ELEFAN runs several times, each time removing the catch vector of one of the sampling times. Another new optimisation routine is based on generic algorithms and is applied by:

```{r Figure 5, fig.height=5, fig.width=5, eval=TRUE, results="hide", fig.cap="Score graph of the ELEFAN method with genetic algorithms. Green dots indicate the runnning maximum value of the fitness function, while blue dots indicate the mean score of each iteration."}
# run ELEFAN with genetic algorithm
res_GA <- ELEFAN_GA(synLFQ7a, MA = 5, seasonalised = TRUE, maxiter = 50, addl.sqrt = FALSE,
                    low_par = list(Linf = 119, K = 0.01, t_anchor = 0, C = 0, ts = 0),
                    up_par = list(Linf = 139, K = 1, t_anchor = 1, C = 1, ts = 1),
                    monitor = FALSE)
# show results
res_GA$par; res_GA$Rn_max
```

The generation number of the ELEFAN_GA was set to only 50 generations (argument 'maxiter'), which returns following results: $L_{inf}$ = `r {round(res_GA$par$Linf,2)}`, K = `r {round(res_GA$par$K,2)}`, $t_{anchor}$ = `r {round(res_GA$par$t_anchor,2)}`, C = `r {round(res_GA$par$C,2)}`, and $t_s$ = `r {round(res_GA$par$ts,2)}` with a score value ($Rn_{max}$) of `r {round(res_GA$Rn_max,2)}`. As with ELEFAN_SA the generation number was hold down due to the vignette format and should be increased in order to find more stable results.
According to [@Pauly1980] it is not possible to estimate $t_{0}$ (theoretical age at length zero) from LFQ data alone. However, this parameter does not influence results of the methods of the traditional stock assessment workflow (catch curve, VPA/CA, and yield per recruit model) and can be set to zero (Mildenberger, unpublished). The ELEFAN methods in this package do not return starting points as FiSAT II users might be used to. Instead, they return the parameter "t_anchor", which describes the fraction of the year where yearly repeating growth curves cross length equal to zero; for example a value of 0.25 refers to April 1st of any year. The maximum age is estimated within the ELEFAN function: it is the age when length is 0.95 $L_{inf}$. However, this value can also be fixed with the argument "agemax", when alternative information about the maximum age of the fish species is available.

The fit of estimated growth parameters can also be explored visually and indicates high similarity with true growth curves and a good fit through the peaks of the LFQ data.

```{r Figure 6, echo = TRUE, fig.cap="Graphical fit of estimated and true growth curves plotted through the length frequency data. The growth curves with the true values are displayed in grey, while the blue and green curves represent the curves of ELEFAN_SA and ELEFAN_GA, respectively."}
# plot LFQ and growth curves
plot(lfqbin, Fname = "rcounts",date.axis = "modern", ylim=c(0,130))
lt <- lfqFitCurves(synLFQ7a, par = list(Linf=123, K=0.2, t_anchor=0.25, C=0.3, ts=0),
                   draw = TRUE, col = "grey", lty = 1, lwd=1.5)
# lt <- lfqFitCurves(synLFQ7, par = res_RSA$par,
#                    draw = TRUE, col = "goldenrod1", lty = 1, lwd=1.5)
lt <- lfqFitCurves(synLFQ7a, par = res_SA$par,
                   draw = TRUE, col = "darkblue", lty = 1, lwd=1.5)
lt <- lfqFitCurves(synLFQ7a, par = res_GA$par,
                   draw = TRUE, col = "darkgreen", lty = 1, lwd=1.5)
```

For further analysis, we use the outcomes of the simulated annealing approach by adding them to the Thumbprint Emperor data list.

```{r}
# assign estimates to the data list
synLFQ7a <- c(synLFQ7a, res_SA$par)
class(synLFQ7a) <- "lfq"
```

####*Natural mortality*
The instantaneous natural mortality rate (M) is an influential parameter of stock assessment models and its estimation is challenging [@Kenchington2014; @Powers2014]. When no controlled experiments or tagging data is available the main approach for its estimation is to use empirical formulas. Overall, there are at least 30 different empirical formulas for the estimation of this parameter [@Kenchington2014] relying on correlations with life history parameters and/or environmental information. We apply the most recent formula, which is based upon a meta-analysis of 201 fish species [@Then2015]. This method requires estimates of the VBGF growth parameters [$L_{inf}$ and K; @Then2015].

```{r, echo=TRUE}
# estimation of M
Ms <- M_empirical(Linf = res_SA$par$Linf, K_l = res_SA$par$K, method = "Then_growth")
synLFQ7a$M <- as.numeric(Ms)
# show results
paste("M =", as.numeric(Ms))
```

The result is a natural mortality of `r {round(as.numeric(Ms),2)}` year$^{-1}$.

###*Fisheries aspects*
####*Exploitation level*
In order to estimate the level of exploitation, knowledge on fishing mortality (F) (usually derived by subtracting natural mortality from total mortality) and gear selectivity is necessary. The length-converted catch curve allows the estimation of the instantaneous total mortality rate (Z) of LFQ data and the derivation of a selection ogive. Here we skip an in-depth selectivity exploration, because more data would be required for this assessment^[For a comprehensive description of selectivity estimation refer to @Millar1997b.]. The following approach assumes a logistic selection ogive, typical for trawl-net selectivity, which may provide an appropriate first estimate in the case of LFQ data derived from a mixture of gears.
Total mortality rate is estimated with a sample of the catch representative for the whole year. Besides, changing the bin size, the function `lfqModify` allows to rearrange the catch matrix in the required format (catch vector per year) and to pool the largest length classes with only a few individuals into a plus group (necessary later for the cohort analysis). As with the Powell-Wetherall method, the `reg_int` argument is necessary to avoid the interactive plotting function (more information in `help(catchCurve)`). The argument `calc_ogive` allows the estimation of the selection ogive.

```{r Figure 7,echo=TRUE, fig.width=6, fig.height=5, fig.cap="Catch curve with selected points for the regression analysis and in the second panel the selection ogive with age at first capture.", message = FALSE, warning=FALSE}
# summarise catch matrix into vector and add plus group which is smaller than Linf
synLFQ7b <- lfqModify(synLFQ7a, vectorise_catch = TRUE, plus_group = 118)
# run catch curve
res_cc <- catchCurve(synLFQ7b, reg_int = c(8,26), calc_ogive = TRUE)
# assign estimates to the data list
synLFQ7b$Z <- res_cc$Z
synLFQ7b$FM <- as.numeric(synLFQ7b$Z - synLFQ7b$M)
synLFQ7b$E <- synLFQ7b$FM/synLFQ7b$Z
```
```{r, echo=FALSE, eval=TRUE}
paste("Z =",round(synLFQ7b$Z,2))
paste("FM =",round(synLFQ7b$FM,2))
paste("E =",round(synLFQ7b$E,2))
paste("L50 =",round(res_cc$L50,2))
```

The catch curve analysis returns a Z value of `r {round(synLFQ7b$Z,2)}` $year^{-1}$. By subtracting M from Z, the fishing mortality rate is derived: `r {round(synLFQ7b$FM,2)}` $year^{-1}$. The exploitation rate is defined as $E = F/Z$ and in this example `r {round(synLFQ7b$E,2)}` The selectivity function of the catch curve estimated a length at first capture ($L_{50}$) of `r {round(res_cc$L50,2)}` cm.

###*Stock size and status*
####*Stock size and composition*
The stock size and fishing mortality per length class can be estimated with Jones' length converted cohort analysis [CA, @Jones1984] - a modification of Pope's virtual population analysis (VPA) for LFQ data. It requires the estimates from preceeding analysis and in addition the parameters a and b of the allometric length-weight relationship^[Here the true parameters of a = 0.015 and b = 3 are used assuming that this was calculated from length-weight data.]. Furthermore, CA needs an estimate for the terminal fishing mortality (`terminal_F`), which was set here to the result of the catch curve minus natural mortality (`r {round(synLFQ7b$FM,2)}`^[For a discussion on this parameter see @Hilborn1992]). The cohort analysis estimates the stock size based on the total catches, it is therefore necessary that the catch vector is representative for the full stock and for all fisheries catches targeting this stock. The argument "catch_corFac" can be used to raise the catches to be yearly or spatially representative. Here I assume that all fisheries targeting the stock were sampled and the catch during the four missing months corresponds to the average monthly catch (`catch_corFac` = (1 + 4/12)). The use of the function lfqModify with the argument "plus_group" is necessary as CA does not allow length classes larger than $L_{inf}$. If the argument "plus_group" is set to `TRUE` only, the function shows the catches per length class and asks the user to enter a length class corresponding to the length class of the new "plus group". If "plus_group" is set to a numeric (here 122, which is just below $L_{inf}$), the plus group is created at this length class (numeric has to correspond to existing length class in vector "midLengths").

```{r Figure 8, echo=TRUE, fig.cap="Results of Jones' cohort analysis (CA).", message=FALSE,warning=FALSE}
synLFQ7c <- synLFQ7b

# assign length-weight parameters to the data list
synLFQ7c$a <- 0.015
synLFQ7c$b <- 3
# run CA
vpa_res <- VPA(param = synLFQ7c, terminalF = synLFQ7c$FM,
               analysis_type = "CA",
               plot=TRUE, catch_corFac = (1+4/12))
# stock size
sum(vpa_res$annualMeanNr, na.rm =TRUE) / 1e3
# stock biomass
sum(vpa_res$meanBiomassTon, na.rm = TRUE)
# assign F per length class to the data list
synLFQ7c$FM <- vpa_res$FM_calc
```

The results show the logistic shaped fishing pattern across length classes (red line in CA plot). The size of the stock is returned in numbers and biomass and according to this method `r {round(sum(vpa_res$annualMeanNr, na.rm =TRUE))}` individuals and `r {round(sum(vpa_res$meanBiomassTon, na.rm = TRUE))}` tons, respectively.

####*Yield per recruit modelling*
Prediction models (or per-recruit models, e.g. Thompson and Bell model) allow to evaluate the status of a fish stock in relation to reference levels and to infer input control measures, such as restricting fishing effort or regulating gear types and mesh sizes. By default the Thompson and Bell model assumes knife edge selection ($L_{25}$ = $L_{50}$ = $L_{75}$)^[Note that the length at capture has 2 abbreviations $L_{50}$ and $L_c$.]; however, the parameter `s_list` allows for changes of the selectivity assumptions. The parameter `FM_change` determines the range of the fishing mortality for which to estimate the yield and biomass trajectories. In the second application of this model, the impact of mesh size restrictions on yield is explored by changing $L_{c}$ (`Lc_change`) and F (`FM_change`, or exploitation rate, `E_change`) simultaneously. The resulting estimates are presented as an isopleth graph showing yield per recruit. By setting the argument `stock_size_1` to 1, all results are per recruit. If the number of recruits (recruitment to the fishery) are known, the exact yield and biomass can be estimated. The arguments `curr.E` and `curr.Lc` allow to derive and visualise yield and biomass (per recruit) values for current fishing patterns.

```{r Figure 9, echo=TRUE, eval=TRUE, fig.cap="Results of the Thompson and Bell model: (a) Curves of yield and biomass per recruit. The black dot represents yield and biomass under current fishing pressure. The yellow and red dashed lines represent fishing mortality for maximum sustainable yield (Fmsy) and fishing mortality to fish the stock at 50% of the virgin biomass (F0.5). (b) exploration of impact of different exploitation rates and Lc values on the relative yield per recruit."}
# Thompson and Bell model with changes in F
TB1 <- predict_mod(synLFQ7c, type = "ThompBell",
                   FM_change = seq(0,1.5,0.05),  stock_size_1 = 1,
                   curr.E = synLFQ7c$E, plot = FALSE, hide.progressbar = TRUE)
# Thompson and Bell model with changes in F and Lc
TB2 <- predict_mod(synLFQ7c, type = "ThompBell",
                   FM_change = seq(0,1.5,0.1), Lc_change = seq(25,50,0.1),
                   stock_size_1 = 1,
                   curr.E = synLFQ7c$E, curr.Lc = res_cc$L50,
                   s_list = list(selecType = "trawl_ogive",
                                 L50 = res_cc$L50, L75 = res_cc$L75),
                   plot = FALSE, hide.progressbar = TRUE)
# plot results
par(mfrow = c(2,1), mar = c(4,5,2,4.5), oma = c(1,0,0,0))
plot(TB1, mark = TRUE)
mtext("(a)", side = 3, at = -1, line = 0.6)
plot(TB2, type = "Isopleth", xaxis1 = "FM", mark = TRUE, contour = 6)
mtext("(b)", side = 3, at = -0.1, line = 0.6)

# Biological reference levels
TB1$df_Es
# Current yield and biomass levels
TB1$currents
```

Please note that the resolution of the $L_c$ and F changes is quite low and the range quite narrow due to the limitations in computation time of the vignette format. The results indicate that the fishing mortality of this example (F = `r {round(synLFQ7b$FM,2)}`) is higher than the maximum fishing mortality ($F_{max} =$ `r {round(TB1$df_Es$Fmsy,2)}`), which confirms the indication of the slightly increased exploitation rate (E = `r {round(synLFQ7b$E,2)}`). The prediction plot shows that the yield could be increased when fishing mortality and mesh size is increased. The units are grams per recruit.


##*Summary*
For management purposes, fish stock assessments are mainly conducted for single species or stocks, which describe the manamgent units of a population. There is much to be gained from multi-species and ecosystem models, but data requirements and complexity make them often unsuitable for deriving management advice. For data-poor fisheries, a traditional fish stock assessment solely based on length-frequency (LFQ) data of one year (as presented here) is particularly useful. LFQ data comes with many advantages over long time series of catch and effort or catch-at-age data [@Mildenberger2016].
In this exercise, the exploitation rate and results of the yield per recruit models indicate that the fiseries is close to sustainable exploitation. The exploration of stock status and fisheries characteristics can of course be extended, but go beyond the scope of this tutorial, which is thought to help getting started with the **`TropFishR`** package. Further details about functions and their arguments can be found in the help files of the functions (`help(...)` or `?..`, where the dots refer to any function of the package). Also the two publications by @Mildenberger2016 and by @Taylor2016 provide more details about the functionality and context of the package.


##*Author's comment*
If you have comments or questions please write an [email](mailto:t.k.mildenberger@gmail.com) or post an issue at [GitHub](https://github.com/tokami/TropFishR/issues). You can follow the development of **`TropFishR`** on [ResearchGate](https://www.researchgate.net/project/TropFishR?_esc=homefeed&_viewIds%5B0%5D=hVPmo2RDCok60qGq2z0JOroN&_viewIds%5B1%5D=zyj0j6jnUgNvrPXMrG9rouAP).


##*References*

